{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a49a94c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('../makemore/names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e58dce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3b0c6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "g = torch.Generator().manual_seed(2147483647)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3eeee145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". e\n",
      "e m\n",
      "m m\n",
      "m a\n",
      "a .\n",
      "tensor([ 0,  5, 13, 13,  1])\n",
      "tensor([ 5, 13, 13,  1,  0])\n"
     ]
    }
   ],
   "source": [
    "# creating dataset of bigrams: (x,y)\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words[:1]:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        print(ch1, ch2)\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "print(xs)\n",
    "print(ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b1d2d9",
   "metadata": {},
   "source": [
    "### Encoding the integers made above from chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3d1658d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "xenc = F.one_hot(xs, num_classes = 27).float()\n",
    "xenc, xenc.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b06eda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1672fb350>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0578b1b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = torch.randn((27, 27), generator=g)\n",
    "# (xenc @ W).shape\n",
    "\n",
    "# 5, 27 @ 27,  1 --> 5, 1\n",
    "# 5, 27 @ 27, 27 --> 5, 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b4f9fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 27])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = xenc @ W # log-counts\n",
    "counts = logits.exp() # something like N in bigram count model\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0691a612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "bigram example 1: .e (indexes 0,5)\n",
      "input to the neural net:  0\n",
      "output probabilities from the neural net:  tensor([0.0570, 0.0085, 0.0442, 0.0297, 0.0840, 0.0141, 0.0222, 0.0063, 0.0098,\n",
      "        0.0638, 0.0062, 0.0264, 0.0099, 0.0601, 0.0169, 0.0745, 0.0025, 0.0156,\n",
      "        0.0456, 0.0726, 0.0243, 0.0781, 0.0769, 0.0333, 0.0115, 0.0348, 0.0713])\n",
      "label (actual next character):  5\n",
      "probability assigned by the net to the correct character:  0.014059726148843765\n",
      "log likelihood:  -4.264441013336182\n",
      "negative log likelihood:  4.264441013336182\n",
      "---------------\n",
      "bigram example 2: em (indexes 5,13)\n",
      "input to the neural net:  5\n",
      "output probabilities from the neural net:  tensor([0.0749, 0.0130, 0.0365, 0.0525, 0.0243, 0.0163, 0.0243, 0.0145, 0.0101,\n",
      "        0.0105, 0.0261, 0.0266, 0.0224, 0.0782, 0.0451, 0.0133, 0.0572, 0.0207,\n",
      "        0.0304, 0.1077, 0.0666, 0.0122, 0.0315, 0.0146, 0.0508, 0.0371, 0.0823])\n",
      "label (actual next character):  13\n",
      "probability assigned by the net to the correct character:  0.07822681963443756\n",
      "log likelihood:  -2.548142671585083\n",
      "negative log likelihood:  2.548142671585083\n",
      "---------------\n",
      "bigram example 3: mm (indexes 13,13)\n",
      "input to the neural net:  13\n",
      "output probabilities from the neural net:  tensor([0.1595, 0.0293, 0.0586, 0.0088, 0.1221, 0.0163, 0.0035, 0.0295, 0.0088,\n",
      "        0.0023, 0.0369, 0.0218, 0.0067, 0.0198, 0.0114, 0.2166, 0.0409, 0.0105,\n",
      "        0.0100, 0.0140, 0.0131, 0.0147, 0.0313, 0.0675, 0.0343, 0.0031, 0.0090])\n",
      "label (actual next character):  13\n",
      "probability assigned by the net to the correct character:  0.019781677052378654\n",
      "log likelihood:  -3.922999143600464\n",
      "negative log likelihood:  3.922999143600464\n",
      "---------------\n",
      "bigram example 4: ma (indexes 13,1)\n",
      "input to the neural net:  13\n",
      "output probabilities from the neural net:  tensor([0.1595, 0.0293, 0.0586, 0.0088, 0.1221, 0.0163, 0.0035, 0.0295, 0.0088,\n",
      "        0.0023, 0.0369, 0.0218, 0.0067, 0.0198, 0.0114, 0.2166, 0.0409, 0.0105,\n",
      "        0.0100, 0.0140, 0.0131, 0.0147, 0.0313, 0.0675, 0.0343, 0.0031, 0.0090])\n",
      "label (actual next character):  1\n",
      "probability assigned by the net to the correct character:  0.029309283941984177\n",
      "log likelihood:  -3.529850959777832\n",
      "negative log likelihood:  3.529850959777832\n",
      "---------------\n",
      "bigram example 5: a. (indexes 1,0)\n",
      "input to the neural net:  1\n",
      "output probabilities from the neural net:  tensor([0.0149, 0.1159, 0.0096, 0.0151, 0.0693, 0.0682, 0.0921, 0.0189, 0.0103,\n",
      "        0.0085, 0.1268, 0.0429, 0.0328, 0.0063, 0.0166, 0.0048, 0.0541, 0.0387,\n",
      "        0.0162, 0.0084, 0.0137, 0.0408, 0.0444, 0.0198, 0.0356, 0.0621, 0.0131])\n",
      "label (actual next character):  0\n",
      "probability assigned by the net to the correct character:  0.014884921722114086\n",
      "log likelihood:  -4.207406520843506\n",
      "negative log likelihood:  4.207406520843506\n",
      "==============\n",
      "average negative log likelihood, i.e. loss =  3.694567918777466\n"
     ]
    }
   ],
   "source": [
    "nlls = torch.zeros(5)\n",
    "for i in range(5):\n",
    "    # i-th bigram\n",
    "    x = xs[i].item()\n",
    "    y = ys[i].item()\n",
    "    print(\"---------------\")\n",
    "    print(f'bigram example {i+1}: {itos[x]}{itos[y]} (indexes {x},{y})')\n",
    "    print('input to the neural net: ', x)\n",
    "    print('output probabilities from the neural net: ', probs[i])\n",
    "    print('label (actual next character): ', y)\n",
    "    p = probs[i,y]\n",
    "    print('probability assigned by the net to the correct character: ', p.item())\n",
    "    logp = torch.log(p)\n",
    "    print('log likelihood: ', logp.item())\n",
    "    nll = -logp\n",
    "    print('negative log likelihood: ', nll.item())\n",
    "    nlls[i] = nll\n",
    "\n",
    "print(\"==============\")\n",
    "print('average negative log likelihood, i.e. loss = ', nlls.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "de0a276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5b4b912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "logits = xenc @ W # log-counts\n",
    "counts = logits.exp() # something like N in bigram count model\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "loss = -probs[torch.arange(5),ys].log().mean() # -ve log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e63b1b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7091541290283203"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4771f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5ae1e319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs[torch.arange(5),ys]#probabilities nn assigns to correct next chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "11afce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "W.grad = None # set the gradient to 0\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "255473b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W.grad.shape, W.shape\n",
    "# every element in W.grad is telling us the influence of that weight on loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c4d00828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update\n",
    "W.data += -0.1 * W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4a32b8",
   "metadata": {},
   "source": [
    "### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6f76f414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  228146\n"
     ]
    }
   ],
   "source": [
    "# creating dataset of bigrams: (x,y)\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print(\"number of examples: \", num)\n",
    "\n",
    "# initialize the network\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8cb99787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.749866247177124\n",
      "3.3659558296203613\n",
      "3.150949001312256\n",
      "3.018296957015991\n",
      "2.9262173175811768\n",
      "2.859292507171631\n",
      "2.808873176574707\n",
      "2.769418239593506\n",
      "2.7375104427337646\n",
      "2.7110233306884766\n",
      "2.688598871231079\n",
      "2.6693389415740967\n",
      "2.65262508392334\n",
      "2.638009548187256\n",
      "2.6251513957977295\n",
      "2.6137807369232178\n",
      "2.6036765575408936\n",
      "2.5946543216705322\n",
      "2.5865609645843506\n",
      "2.579267740249634\n",
      "2.5726659297943115\n",
      "2.5666637420654297\n",
      "2.561185121536255\n",
      "2.556164026260376\n",
      "2.551546812057495\n",
      "2.547285318374634\n",
      "2.5433406829833984\n",
      "2.5396790504455566\n",
      "2.536271810531616\n",
      "2.5330939292907715\n",
      "2.5301244258880615\n",
      "2.52734375\n",
      "2.5247366428375244\n",
      "2.5222878456115723\n",
      "2.5199849605560303\n",
      "2.5178165435791016\n",
      "2.5157716274261475\n",
      "2.513841390609741\n",
      "2.512017011642456\n",
      "2.5102908611297607\n",
      "2.508655548095703\n",
      "2.5071051120758057\n",
      "2.5056331157684326\n",
      "2.5042340755462646\n",
      "2.502903461456299\n",
      "2.501636505126953\n",
      "2.5004289150238037\n",
      "2.4992763996124268\n",
      "2.498176336288452\n",
      "2.497124671936035\n",
      "2.4961185455322266\n",
      "2.495154857635498\n",
      "2.494231700897217\n",
      "2.4933464527130127\n",
      "2.4924962520599365\n",
      "2.4916796684265137\n",
      "2.4908945560455322\n",
      "2.4901392459869385\n",
      "2.489412546157837\n",
      "2.488711357116699\n",
      "2.4880363941192627\n",
      "2.4873850345611572\n",
      "2.4867560863494873\n",
      "2.4861485958099365\n",
      "2.4855616092681885\n",
      "2.4849939346313477\n",
      "2.4844446182250977\n",
      "2.483912944793701\n",
      "2.483397960662842\n",
      "2.4828989505767822\n",
      "2.482414960861206\n",
      "2.4819459915161133\n",
      "2.48149037361145\n",
      "2.481048345565796\n",
      "2.480618953704834\n",
      "2.4802021980285645\n",
      "2.479796886444092\n",
      "2.479402780532837\n",
      "2.4790191650390625\n",
      "2.4786462783813477\n",
      "2.478283405303955\n",
      "2.4779303073883057\n",
      "2.477585792541504\n",
      "2.477250576019287\n",
      "2.476923704147339\n",
      "2.4766054153442383\n",
      "2.476294755935669\n",
      "2.47599196434021\n",
      "2.475696563720703\n",
      "2.4754085540771484\n",
      "2.4751272201538086\n",
      "2.4748528003692627\n",
      "2.4745843410491943\n",
      "2.474322557449341\n",
      "2.474066734313965\n",
      "2.4738166332244873\n",
      "2.4735724925994873\n",
      "2.4733335971832275\n",
      "2.473099946975708\n",
      "2.4728715419769287\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes = 27).float() # input to the network: one-hot encoding\n",
    "    logits = xenc @ W # log-counts\n",
    "    counts = logits.exp() # something like N in bigram count model\n",
    "    probs = counts / counts.sum(1, keepdims=True)\n",
    "    loss = -probs[torch.arange(num),ys].log().mean() # -ve log likelihood\n",
    "    print(loss.item())\n",
    "    # backward pass\n",
    "    W.grad = None # set the gradient to 0\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e01925",
   "metadata": {},
   "source": [
    "### Adding Regularization\n",
    "- Equivalent to smoothing in bigram count model, is something called **Regularization**\n",
    "- It helps in pushing weights towards 0, in order to acheive a more uniform probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "916ba52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  228146\n"
     ]
    }
   ],
   "source": [
    "# creating dataset of bigrams: (x,y)\n",
    "xs, ys = [], []\n",
    "\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print(\"number of examples: \", num)\n",
    "\n",
    "# initialize the network\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b285d53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.768618583679199\n",
      "3.3788065910339355\n",
      "3.161090850830078\n",
      "3.027186155319214\n",
      "2.9344842433929443\n",
      "2.867231607437134\n",
      "2.8166542053222656\n",
      "2.777146339416504\n",
      "2.7452542781829834\n",
      "2.7188305854797363\n",
      "2.696505308151245\n",
      "2.6773722171783447\n",
      "2.6608054637908936\n",
      "2.6463515758514404\n",
      "2.633664846420288\n",
      "2.622471570968628\n",
      "2.6125476360321045\n",
      "2.6037068367004395\n",
      "2.595794916152954\n",
      "2.5886809825897217\n",
      "2.5822560787200928\n",
      "2.576429843902588\n",
      "2.5711236000061035\n",
      "2.566272735595703\n",
      "2.5618228912353516\n",
      "2.5577263832092285\n",
      "2.5539441108703613\n",
      "2.5504424571990967\n",
      "2.5471925735473633\n",
      "2.5441696643829346\n",
      "2.5413525104522705\n",
      "2.538721799850464\n",
      "2.536262035369873\n",
      "2.5339579582214355\n",
      "2.5317976474761963\n",
      "2.5297679901123047\n",
      "2.527860164642334\n",
      "2.5260636806488037\n",
      "2.5243704319000244\n",
      "2.522773027420044\n",
      "2.521263837814331\n",
      "2.519836902618408\n",
      "2.5184857845306396\n",
      "2.5172054767608643\n",
      "2.515990734100342\n",
      "2.5148372650146484\n",
      "2.5137407779693604\n",
      "2.51269793510437\n",
      "2.511704921722412\n",
      "2.5107579231262207\n",
      "2.509854793548584\n",
      "2.5089924335479736\n",
      "2.5081682205200195\n",
      "2.507380485534668\n",
      "2.5066258907318115\n",
      "2.5059032440185547\n",
      "2.5052103996276855\n",
      "2.5045459270477295\n",
      "2.5039076805114746\n",
      "2.503295421600342\n",
      "2.5027060508728027\n",
      "2.5021398067474365\n",
      "2.5015945434570312\n",
      "2.5010693073272705\n",
      "2.500562906265259\n",
      "2.500075578689575\n",
      "2.4996049404144287\n",
      "2.4991507530212402\n",
      "2.4987118244171143\n",
      "2.49828839302063\n",
      "2.4978787899017334\n",
      "2.497483015060425\n",
      "2.4970998764038086\n",
      "2.4967293739318848\n",
      "2.496370315551758\n",
      "2.496022939682007\n",
      "2.4956860542297363\n",
      "2.4953596591949463\n",
      "2.4950428009033203\n",
      "2.4947361946105957\n",
      "2.494438648223877\n",
      "2.494149684906006\n",
      "2.4938690662384033\n",
      "2.4935970306396484\n",
      "2.4933323860168457\n",
      "2.493074893951416\n",
      "2.4928252696990967\n",
      "2.492582321166992\n",
      "2.4923462867736816\n",
      "2.492116928100586\n",
      "2.4918935298919678\n",
      "2.491675853729248\n",
      "2.491464376449585\n",
      "2.491258382797241\n",
      "2.491058111190796\n",
      "2.4908626079559326\n",
      "2.4906721115112305\n",
      "2.4904870986938477\n",
      "2.4903066158294678\n",
      "2.4901301860809326\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(xs, num_classes = 27).float() # input to the network: one-hot encoding\n",
    "    logits = xenc @ W # log-counts\n",
    "    counts = logits.exp() # something like N in bigram count model\n",
    "    probs = counts / counts.sum(1, keepdims=True)\n",
    "    loss = -probs[torch.arange(num),ys].log().mean() + 0.01 * (W**2).mean()\n",
    "    print(loss.item())\n",
    "    # backward pass\n",
    "    W.grad = None # set the gradient to 0\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e899688e",
   "metadata": {},
   "source": [
    "## Sampling from nn model probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1ed2d373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cexze.\n",
      "momasurailezityha.\n",
      "konimittain.\n",
      "llayn.\n",
      "ka.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    ix = 0\n",
    "    out = []\n",
    "    while True:\n",
    "        # p = P[ix]\n",
    "        xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "        logits = xenc @ W\n",
    "        counts = logits.exp()\n",
    "        p = counts / counts.sum(1, keepdims=True)\n",
    "        ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[ix])\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b24cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
