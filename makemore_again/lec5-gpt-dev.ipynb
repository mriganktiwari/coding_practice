{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb2ccc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = open('../makemore/gpt/input.txt', 'r').read()\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93cefc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef703b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40e08f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb731007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "print(encode(\"hii there\"))\n",
    "print(decode(encode(\"hii there\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2830c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e91fb135",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a08b10c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d04fced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56, 57, 58,  1, 15, 47])\n",
      "tensor([47, 56, 57, 58,  1, 15, 47, 58])\n",
      "\n",
      "when input is tensor([18]): target is 47\n",
      "when input is tensor([18, 47]): target is 56\n",
      "when input is tensor([18, 47, 56]): target is 57\n",
      "when input is tensor([18, 47, 56, 57]): target is 58\n",
      "when input is tensor([18, 47, 56, 57, 58]): target is 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]): target is 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]): target is 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]): target is 58\n"
     ]
    }
   ],
   "source": [
    "# illustrate (spell it out with code) the examples a chunk of tokenized integers will make\n",
    "# THIS CAN ALSO BE THOUGHT OF AS TIME DIMENSION\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "print(x)\n",
    "print(y)\n",
    "print()\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[ : t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context}: target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b967969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(9, (2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b26d6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 1, 60, 39, 47, 50,  1, 63, 53],\n",
      "        [46, 43, 39, 60, 43, 52,  1, 44],\n",
      "        [ 1, 46, 43, 56, 43,  1, 63, 53],\n",
      "        [61, 47, 50, 50,  1, 57, 39, 63]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[60, 39, 47, 50,  1, 63, 53, 59],\n",
      "        [43, 39, 60, 43, 52,  1, 44, 53],\n",
      "        [46, 43, 56, 43,  1, 63, 53, 59],\n",
      "        [47, 50, 50,  1, 57, 39, 63,  0]])\n",
      "\n",
      "----------\n",
      "\n",
      "when input is tensor([1]):      target is 60\n",
      "when input is tensor([ 1, 60]):      target is 39\n",
      "when input is tensor([ 1, 60, 39]):      target is 47\n",
      "when input is tensor([ 1, 60, 39, 47]):      target is 50\n",
      "when input is tensor([ 1, 60, 39, 47, 50]):      target is 1\n",
      "when input is tensor([ 1, 60, 39, 47, 50,  1]):      target is 63\n",
      "when input is tensor([ 1, 60, 39, 47, 50,  1, 63]):      target is 53\n",
      "when input is tensor([ 1, 60, 39, 47, 50,  1, 63, 53]):      target is 59\n",
      "when input is tensor([46]):      target is 43\n",
      "when input is tensor([46, 43]):      target is 39\n",
      "when input is tensor([46, 43, 39]):      target is 60\n",
      "when input is tensor([46, 43, 39, 60]):      target is 43\n",
      "when input is tensor([46, 43, 39, 60, 43]):      target is 52\n",
      "when input is tensor([46, 43, 39, 60, 43, 52]):      target is 1\n",
      "when input is tensor([46, 43, 39, 60, 43, 52,  1]):      target is 44\n",
      "when input is tensor([46, 43, 39, 60, 43, 52,  1, 44]):      target is 53\n",
      "when input is tensor([1]):      target is 46\n",
      "when input is tensor([ 1, 46]):      target is 43\n",
      "when input is tensor([ 1, 46, 43]):      target is 56\n",
      "when input is tensor([ 1, 46, 43, 56]):      target is 43\n",
      "when input is tensor([ 1, 46, 43, 56, 43]):      target is 1\n",
      "when input is tensor([ 1, 46, 43, 56, 43,  1]):      target is 63\n",
      "when input is tensor([ 1, 46, 43, 56, 43,  1, 63]):      target is 53\n",
      "when input is tensor([ 1, 46, 43, 56, 43,  1, 63, 53]):      target is 59\n",
      "when input is tensor([61]):      target is 47\n",
      "when input is tensor([61, 47]):      target is 50\n",
      "when input is tensor([61, 47, 50]):      target is 50\n",
      "when input is tensor([61, 47, 50, 50]):      target is 1\n",
      "when input is tensor([61, 47, 50, 50,  1]):      target is 57\n",
      "when input is tensor([61, 47, 50, 50,  1, 57]):      target is 39\n",
      "when input is tensor([61, 47, 50, 50,  1, 57, 39]):      target is 63\n",
      "when input is tensor([61, 47, 50, 50,  1, 57, 39, 63]):      target is 0\n"
     ]
    }
   ],
   "source": [
    "# visualize a batch of data\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data)-batch_size, (batch_size,))\n",
    "    x = torch.stack([data[i : i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1 : i+block_size+1] for i in ix])\n",
    "    return x,y\n",
    "\n",
    "xb,yb = get_batch('train')\n",
    "print(\"inputs:\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print(\"targets:\")\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print(\"\\n----------\\n\")\n",
    "\n",
    "for b in range(batch_size): # batch dimension\n",
    "    for t in range(block_size): # time dimension\n",
    "        context = xb[b, : t+1]\n",
    "        target =  yb[b,     t]\n",
    "        print(f\"when input is {context}:      target is {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83da9e7",
   "metadata": {},
   "source": [
    "## Bigram LM: simplest LM to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85857e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1099c2db0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8aebfed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.6413, grad_fn=<NllLossBackward0>)\n",
      "idx shape after concat:: torch.Size([1, 101])\n",
      "\n",
      "EGXxuxFFW:BkQW bnMoNi&zAyrONl?3XHzQmSBr&XxUnfeyI$aCSZRt:WI,tIGxKuGbOX;K-oRnM.VRFKORh.JCvATdTMv!ZPdiA\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, idx, targets = None):\n",
    "        logits = self.token_embedding_table(idx) # (B, T, C)\n",
    "        \n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B,T) array of indices in current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            \n",
    "            # focus only on the last time step\n",
    "            logits = logits[:,-1,:] # (B, C)\n",
    "            \n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        print(\"idx shape after concat::\", idx.shape)\n",
    "        return idx\n",
    "\n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb,yb)\n",
    "print(logits.shape) # (B*T,C)\n",
    "print(loss)\n",
    "\n",
    "print(decode(m.generate(idx=torch.zeros((1,1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3d756b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16c5bd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.511256694793701\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(1000):\n",
    "    xb, yb = get_batch('train')\n",
    "    \n",
    "    logits, loss = m(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48143509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx shape after concat:: torch.Size([1, 501])\n",
      "\n",
      "ABupth.\n",
      "\n",
      "Busiesed o I cesweven venourimemandel. aron, hald ke DUSouthyowourees g gerone ncr, m Gowiveay hord isa dwn:\n",
      "Sore usoun fonest, arereane f-ery ollan\n",
      "Touinghanor h isokinthat p ilutin, sthe pa soelf ath bear my madeay itheiman byouguomy blineny INur thauthrg msenlchas ave twoufo anaths\n",
      "Wey t\n",
      "AMIOhl d bond, tenowio h d d bo muthounothal our u sepustareamim I w, inoshyo nked itawhary slfor, sice d,\n",
      "3--ENor halt r ge?\n",
      "I HM:\n",
      "\n",
      "GS Sooayonllirthime e:\n",
      "Pr be es ivet\n",
      "NI f nd omed!\n",
      "I aknd beded al\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx=torch.zeros((1,1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8e7ec0",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dc478d",
   "metadata": {},
   "source": [
    "## Some preliminaries work for Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d7c457a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consider a toy example\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27da646c",
   "metadata": {},
   "source": [
    "### Easiest way for the token to communicate can be average out with all previous tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a41fa43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 1\n",
    "# we want x[b,t] = mean_{i<=t} x[b,i]\n",
    "\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] #(t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "08d4299e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b7e222e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390b3f75",
   "metadata": {},
   "source": [
    "#### Efficiently doing the above interaction b/w timesteps incrementaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1902930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2\n",
    "\n",
    "wei = torch.tril(torch.ones(T,T))\n",
    "wei /= wei.sum(dim=1, keepdims=True)\n",
    "wei # weights to do weighted aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c92720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wei.sum(dim=1)#, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "11507701",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow2 = wei @ x # (T,T) @ (B,T,C) --> (B,T,C): Batched matrix mulitply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "023c5350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow2[0] # identical to what we acheive earlier with 2 for-loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "39798578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "19243dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 3\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "19885bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "77e9df5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9a05d12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e1c2d972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.arange(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "daecc503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 16])\n"
     ]
    }
   ],
   "source": [
    "# version 4: self-attention\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# single head performing self-attention\n",
    "head_size = 16\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B, T, head_size)\n",
    "q = query(x) # (B, T, head_size)\n",
    "\n",
    "wei = q @ k.transpose(-2,-1) # (B,T,16) @ (B,16,T) --> (B,T,T)\n",
    "\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "# wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x) # (B, T, head_size)\n",
    "out = wei @ v # (B,T,T) @ (B,T,head_size) --> (B,T,head_size)\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "52b452ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5877, 0.4123, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4457, 0.2810, 0.2733, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2220, 0.7496, 0.0175, 0.0109, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0379, 0.0124, 0.0412, 0.0630, 0.8454, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5497, 0.2187, 0.0185, 0.0239, 0.1831, 0.0062, 0.0000, 0.0000],\n",
       "        [0.2576, 0.0830, 0.0946, 0.0241, 0.1273, 0.3627, 0.0507, 0.0000],\n",
       "        [0.0499, 0.1052, 0.0302, 0.0281, 0.1980, 0.2657, 0.1755, 0.1474]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef67b52",
   "metadata": {},
   "source": [
    "## Understanding how concat with diff dim values works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8712ea80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.8204],\n",
      "         [-0.5869]],\n",
      "\n",
      "        [[-0.3027],\n",
      "         [ 1.4529]],\n",
      "\n",
      "        [[ 1.8694],\n",
      "         [ 1.0485]],\n",
      "\n",
      "        [[-0.2940],\n",
      "         [-0.4703]]]) 3\n",
      "tensor([[[ 0.8907],\n",
      "         [-0.8033]],\n",
      "\n",
      "        [[-0.2139],\n",
      "         [ 1.4153]],\n",
      "\n",
      "        [[-1.2557],\n",
      "         [ 0.4283]],\n",
      "\n",
      "        [[ 1.1396],\n",
      "         [ 1.6915]]]) 3\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(4,2,1)\n",
    "b = torch.randn(4,2,1)\n",
    "print(a, a.ndim)\n",
    "print(b, b.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "870f4d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 4, 1]),\n",
       " tensor([[[-0.8204,  0.8907],\n",
       "          [-0.5869, -0.8033]],\n",
       " \n",
       "         [[-0.3027, -0.2139],\n",
       "          [ 1.4529,  1.4153]],\n",
       " \n",
       "         [[ 1.8694, -1.2557],\n",
       "          [ 1.0485,  0.4283]],\n",
       " \n",
       "         [[-0.2940,  1.1396],\n",
       "          [-0.4703,  1.6915]]]))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([a,b], dim=-2).shape, torch.cat([a,b], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4631bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
